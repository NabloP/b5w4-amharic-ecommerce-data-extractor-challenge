# B5W4: Amharic E-Commerce Data Extractor Challenge â€“ 10 Academy

## ğŸ—‚ Challenge Context
This repository documents the submission for 10 Academyâ€™s **B5W4: Amharic E-Commerce Data Extractor Challenge**.  
The goal is to support EthioMart in becoming Ethiopiaâ€™s centralized hub for Telegram-based e-commerce by:

- Extracting key business entities (product, price, location) from unstructured Amharic Telegram messages  
- Fine-tuning transformer models for accurate Amharic NER  
- Scoring vendors based on their activity, reach, and pricing to enable data-driven micro-lending  

The project simulates the role of a fintech data analyst building a structured NLP pipeline for intelligent vendor profiling.

### Key Features
- ğŸ§² Real-time Telegram scraping of e-commerce messages and metadata  
- âœï¸ CoNLL-format labeling of Amharic text with Product, Price, and Location entities  
- ğŸ¤– Transformer-based fine-tuning (XLM-Roberta, mBERT) for NER extraction  
- ğŸ“Š Vendor-level analytics and micro-lending scorecards  
- ğŸ” Model explainability using SHAP and LIME  

---

## ğŸ”§ Project Setup

### 1. Clone the repository:
git clone https://github.com/NabloP/b5w4-amharic-ecommerce-data-extractor-challenge.git
cd b5w4-amharic-ecommerce-data-extractor-challenge

### 2. Create and activate a virtual environment:
**On Windows (PowerShell):**
python -m venv data-extractor-challenge
data-extractor-challenge\Scripts\Activate.ps1

**On macOS/Linux:**
python3 -m venv data-extractor-challenge
source data-extractor-challenge/bin/activate

### 3. Install dependencies:
pip install -r requirements.txt

---

## ğŸ“ Project Structure

<!-- TREE START -->
b5w4-amharic-ecommerce-data-extractor-challenge/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ cleaned/
â”‚   â”œâ”€â”€ labeled/
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ logs/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ labeling/
â”‚   â”œâ”€â”€ modeling/
â”‚   â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ analytics/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest_data.py
â”‚   â”œâ”€â”€ label_data.py
â”‚   â”œâ”€â”€ fine_tune_model.py
â”‚   â”œâ”€â”€ evaluate_models.py
â”‚   â””â”€â”€ generate_scorecards.py
â”œâ”€â”€ notebooks/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
<!-- TREE END -->

---

## âœ… Status
- â˜‘ï¸ Task 1 complete: Ingested Telegram data from 5+ vendors, preprocessed and normalized Amharic messages  
- â˜‘ï¸ Task 2 complete: Manually labeled 50+ messages in CoNLL format  
- â¬œ Task 3: Fine-tuning underway using XLM-Roberta and Hugging Face pipeline  
- â¬œ Task 4: Model evaluation and comparison to be completed  
- â¬œ Task 5: SHAP & LIME interpretation pending  
- â¬œ Task 6: Vendor scorecard module in progress  

---

## âœï¸ Task 2: Manual Labeling for Amharic NER

In this task, we prepared a supervised training dataset for fine-tuning transformer models on Amharic Named Entity Recognition (NER). The steps included:

- ğŸ§ª Sampling 50 diverse, product-rich messages from the cleaned Telegram corpus
- ğŸ“„ Translating and tokenizing each message to support annotation
- ğŸ”– Manually labeling key entities (`B-BRAND`, `B-PRICE`, `B-SIZE`, `B-LOCATION`, `B-CONTACT`) using CoNLL-2003 format
- ğŸ§¹ Using regex and heuristics to consistently annotate entities across vendors and formats
- ğŸ“ Saving the structured labels to `data/labeled/labeled_messages.txt` for use in Task 3 model training

This labeling task sets the foundation for our transformer-based NER pipeline and is designed for scalability across thousands of messages in future iterations.

---

## ğŸ“¦ Key Capabilities
- âœ… Real-time ingestion from Telegram via Telethon  
- âœ… Amharic-friendly tokenization and text normalization  
- âœ… CoNLL-format labeling and entity alignment  
- âœ… Hugging Face-based model fine-tuning for NER  
- âœ… Scorecard logic to support lending decisions  

---

## ğŸ§  Design Philosophy
This project emphasizes:

- ğŸ“¦ Modular folder and code design (reusable Python classes)  
- ğŸ” Reproducibility via `requirements.txt` and consistent naming  
- ğŸ§ª Explainability using SHAP and LIME  
- ğŸ” Transparency in scoring logic for vendor prioritization  

---

## ğŸš€ Author
Nabil Mohamed  
10 Academy Bootcamp â€“ B5W4 Cohort  
GitHub: https://github.com/NabloP